#!/usr/bin/env python3
"""
マスク + 深度マップ → 3Dメッシュ/点群変換

SAM3で生成したマスクと深度マップを組み合わせて、
セグメントされた領域を3Dオブジェクトとして出力します。

使い方:
    # 点群（PLY）として出力
    python -m server.phase2_full.mask_to_3d \
        --mask experiments/sam3_demo_mask.npy \
        --depth test_data/depth_001.npy \
        --rgb test_data/rgb_001.jpg \
        --output experiments/segmented_object.ply

    # Blenderでインポート
    # File > Import > Stanford (.ply)
"""

import os
import sys
import argparse
import numpy as np
from PIL import Image


def load_depth(depth_path: str) -> np.ndarray:
    """深度マップを読み込む"""
    if depth_path.endswith('.npy'):
        depth = np.load(depth_path)
    elif depth_path.endswith(('.png', '.jpg', '.jpeg')):
        # 16-bit PNG or normalized image
        depth_img = Image.open(depth_path)
        depth = np.array(depth_img).astype(np.float32)
        # 正規化されている場合はスケーリング
        if depth.max() <= 1.0:
            depth = depth * 10.0  # 仮のスケール（実際のデータに合わせて調整）
        elif depth.max() <= 255:
            depth = depth / 255.0 * 10.0
        elif depth.max() <= 65535:
            depth = depth / 65535.0 * 10.0
    else:
        raise ValueError(f"Unsupported depth format: {depth_path}")

    return depth


def load_mask(mask_path: str) -> np.ndarray:
    """マスクを読み込む"""
    if mask_path.endswith('.npy'):
        mask = np.load(mask_path)
    elif mask_path.endswith(('.png', '.jpg', '.jpeg')):
        mask_img = Image.open(mask_path).convert('L')
        mask = np.array(mask_img) > 128
    else:
        raise ValueError(f"Unsupported mask format: {mask_path}")

    return mask.astype(bool)


def load_rgb(rgb_path: str) -> np.ndarray:
    """RGB画像を読み込む"""
    img = Image.open(rgb_path).convert('RGB')
    return np.array(img)


def depth_to_pointcloud(
    depth: np.ndarray,
    rgb: np.ndarray = None,
    mask: np.ndarray = None,
    fx: float = None,
    fy: float = None,
    cx: float = None,
    cy: float = None,
) -> tuple:
    """
    深度マップを点群に変換

    Args:
        depth: 深度マップ (H, W)
        rgb: RGB画像 (H, W, 3)、オプション
        mask: マスク (H, W)、Trueの領域のみ抽出
        fx, fy: 焦点距離（ピクセル単位）
        cx, cy: 主点（画像中心）

    Returns:
        points: 3D座標 (N, 3)
        colors: RGB色 (N, 3)、rgbがNoneの場合はNone
    """
    h, w = depth.shape[:2]

    # カメラパラメータのデフォルト値（一般的なカメラを仮定）
    if fx is None:
        fx = w  # 仮の焦点距離
    if fy is None:
        fy = h
    if cx is None:
        cx = w / 2
    if cy is None:
        cy = h / 2

    # ピクセル座標のグリッドを作成
    u = np.arange(w)
    v = np.arange(h)
    u, v = np.meshgrid(u, v)

    # 3D座標を計算
    z = depth
    x = (u - cx) * z / fx
    y = (v - cy) * z / fy

    # 点群を作成
    points = np.stack([x, y, z], axis=-1)  # (H, W, 3)

    # マスクを適用
    if mask is not None:
        valid = mask & (z > 0)  # マスク領域かつ有効な深度
    else:
        valid = z > 0

    points = points[valid]  # (N, 3)

    # 色情報
    colors = None
    if rgb is not None:
        colors = rgb[valid]  # (N, 3)

    return points, colors


def save_ply(
    filepath: str,
    points: np.ndarray,
    colors: np.ndarray = None,
):
    """
    PLY形式で点群を保存（Blenderでインポート可能）

    Args:
        filepath: 出力ファイルパス
        points: 3D座標 (N, 3)
        colors: RGB色 (N, 3)、0-255
    """
    n_points = len(points)

    with open(filepath, 'w') as f:
        # ヘッダー
        f.write("ply\n")
        f.write("format ascii 1.0\n")
        f.write(f"element vertex {n_points}\n")
        f.write("property float x\n")
        f.write("property float y\n")
        f.write("property float z\n")
        if colors is not None:
            f.write("property uchar red\n")
            f.write("property uchar green\n")
            f.write("property uchar blue\n")
        f.write("end_header\n")

        # データ
        for i in range(n_points):
            x, y, z = points[i]
            if colors is not None:
                r, g, b = colors[i].astype(int)
                f.write(f"{x:.6f} {y:.6f} {z:.6f} {r} {g} {b}\n")
            else:
                f.write(f"{x:.6f} {y:.6f} {z:.6f}\n")

    print(f"Saved {n_points} points to {filepath}")


def save_obj(
    filepath: str,
    points: np.ndarray,
    colors: np.ndarray = None,
):
    """
    OBJ形式で点群を保存（頂点のみ）

    Args:
        filepath: 出力ファイルパス
        points: 3D座標 (N, 3)
        colors: RGB色 (N, 3)、0-255（OBJではコメントとして保存）
    """
    n_points = len(points)

    with open(filepath, 'w') as f:
        f.write(f"# Point cloud with {n_points} vertices\n")
        f.write("# Generated by mask_to_3d.py\n\n")

        for i in range(n_points):
            x, y, z = points[i]
            if colors is not None:
                r, g, b = colors[i] / 255.0  # OBJは0-1の色
                f.write(f"v {x:.6f} {y:.6f} {z:.6f} {r:.4f} {g:.4f} {b:.4f}\n")
            else:
                f.write(f"v {x:.6f} {y:.6f} {z:.6f}\n")

    print(f"Saved {n_points} vertices to {filepath}")


def mask_to_3d(
    mask_path: str,
    depth_path: str,
    rgb_path: str = None,
    output_path: str = None,
    fx: float = None,
    fy: float = None,
    cx: float = None,
    cy: float = None,
) -> dict:
    """
    マスク + 深度マップ → 3D点群変換のメイン関数

    Args:
        mask_path: SAM3マスクファイル（.npy or .png）
        depth_path: 深度マップファイル（.npy or .png）
        rgb_path: RGB画像ファイル（オプション）
        output_path: 出力ファイルパス（.ply or .obj）
        fx, fy, cx, cy: カメラパラメータ

    Returns:
        dict: 結果情報
    """
    # ファイル読み込み
    print(f"Loading mask: {mask_path}")
    mask = load_mask(mask_path)

    print(f"Loading depth: {depth_path}")
    depth = load_depth(depth_path)

    rgb = None
    if rgb_path:
        print(f"Loading RGB: {rgb_path}")
        rgb = load_rgb(rgb_path)

    # サイズ確認
    if mask.shape != depth.shape[:2]:
        print(f"Warning: Mask shape {mask.shape} != Depth shape {depth.shape[:2]}")
        # リサイズ
        from PIL import Image as PILImage
        mask_img = PILImage.fromarray(mask.astype(np.uint8) * 255)
        mask_img = mask_img.resize((depth.shape[1], depth.shape[0]), PILImage.NEAREST)
        mask = np.array(mask_img) > 128

    if rgb is not None and rgb.shape[:2] != depth.shape[:2]:
        print(f"Warning: RGB shape {rgb.shape[:2]} != Depth shape {depth.shape[:2]}")
        rgb_img = PILImage.fromarray(rgb)
        rgb_img = rgb_img.resize((depth.shape[1], depth.shape[0]), PILImage.BILINEAR)
        rgb = np.array(rgb_img)

    # 点群に変換
    print("Converting to point cloud...")
    points, colors = depth_to_pointcloud(
        depth, rgb, mask,
        fx=fx, fy=fy, cx=cx, cy=cy
    )

    print(f"Generated {len(points)} points from masked region")

    # 出力
    if output_path:
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)

        if output_path.endswith('.ply'):
            save_ply(output_path, points, colors)
        elif output_path.endswith('.obj'):
            save_obj(output_path, points, colors)
        else:
            # デフォルトはPLY
            output_path = output_path + '.ply'
            save_ply(output_path, points, colors)

    return {
        'n_points': len(points),
        'points': points,
        'colors': colors,
        'output_path': output_path,
        'mask_coverage': mask.sum() / mask.size * 100,
    }


def main():
    parser = argparse.ArgumentParser(
        description="マスク + 深度マップ → 3D点群変換"
    )
    parser.add_argument(
        "--mask", required=True,
        help="SAM3マスクファイル（.npy or .png）"
    )
    parser.add_argument(
        "--depth", required=True,
        help="深度マップファイル（.npy or .png）"
    )
    parser.add_argument(
        "--rgb",
        help="RGB画像ファイル（オプション、色付き点群用）"
    )
    parser.add_argument(
        "--output", "-o",
        default="experiments/segmented_object.ply",
        help="出力ファイルパス（.ply or .obj）"
    )
    parser.add_argument(
        "--fx", type=float,
        help="焦点距離 fx（ピクセル単位）"
    )
    parser.add_argument(
        "--fy", type=float,
        help="焦点距離 fy（ピクセル単位）"
    )
    parser.add_argument(
        "--cx", type=float,
        help="主点 cx"
    )
    parser.add_argument(
        "--cy", type=float,
        help="主点 cy"
    )

    args = parser.parse_args()

    result = mask_to_3d(
        mask_path=args.mask,
        depth_path=args.depth,
        rgb_path=args.rgb,
        output_path=args.output,
        fx=args.fx,
        fy=args.fy,
        cx=args.cx,
        cy=args.cy,
    )

    print("\n" + "=" * 50)
    print("変換完了!")
    print(f"  点の数: {result['n_points']}")
    print(f"  マスク領域: {result['mask_coverage']:.1f}%")
    print(f"  出力: {result['output_path']}")
    print("=" * 50)
    print("\nBlenderでインポート:")
    print("  File > Import > Stanford (.ply)")


if __name__ == "__main__":
    main()
