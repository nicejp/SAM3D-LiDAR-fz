#!/usr/bin/env python3
"""
SAM 3 Interactive Demo
Meta AIã®ãƒ‡ãƒ¢ã‚µã‚¤ãƒˆã®ã‚ˆã†ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

ä½¿ã„æ–¹:
    # Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œ
    export PYTHONPATH=/workspace:/workspace/sam3:$PYTHONPATH
    cd /workspace
    python -m server.phase2_full.sam3_demo

    # ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://<ã‚µãƒ¼ãƒãƒ¼IP>:7860 ã«ã‚¢ã‚¯ã‚»ã‚¹
"""

import os
import sys

# PYTHONPATHã®è¨­å®š
if "/workspace/sam3" not in sys.path:
    sys.path.insert(0, "/workspace/sam3")
if "/workspace" not in sys.path:
    sys.path.insert(0, "/workspace")

import numpy as np
from PIL import Image
import torch

# Gradioã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import gradio as gr
except ImportError:
    print("GradioãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
    print("  pip install gradio")
    sys.exit(1)

# SAM3ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from sam3 import build_sam3_image_model
    from sam3.model.sam3_image_processor import Sam3Processor
    import sam3
    HAS_SAM3 = True
except ImportError:
    HAS_SAM3 = False
    print("SAM 3ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)


class SAM3Demo:
    """SAM3ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢"""

    def __init__(self):
        self.model = None
        self.processor = None
        self.current_image = None
        self.current_image_path = None  # ç”»åƒãƒ‘ã‚¹ã‚’ä¿å­˜
        self.inference_state = None
        self.click_points = []
        self.click_labels = []

    def load_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if self.model is not None:
            return

        print("SAM 3ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")

        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        if torch.cuda.is_available():
            torch.autocast("cuda", dtype=torch.bfloat16).__enter__()

        # BPEãƒ‘ã‚¹ã‚’å–å¾—
        sam3_root = os.path.join(os.path.dirname(sam3.__file__), "..")
        bpe_path = os.path.join(sam3_root, "assets", "bpe_simple_vocab_16e6.txt.gz")

        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ“ãƒ«ãƒ‰
        self.model = build_sam3_image_model(
            bpe_path=bpe_path,
            device="cuda" if torch.cuda.is_available() else "cpu",
            eval_mode=True,
            enable_inst_interactivity=True,
            load_from_HF=True
        )

        # ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ä½œæˆ
        self.processor = Sam3Processor(self.model)
        print("SAM 3ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")

    def set_image(self, image):
        """ç”»åƒã‚’è¨­å®š"""
        if image is None:
            return None, "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

        try:
            self.load_model()

            self.current_image = image.copy()
            self.click_points = []
            self.click_labels = []

            # PIL Imageã«å¤‰æ›
            pil_image = Image.fromarray(image)
            self.inference_state = self.processor.set_image(pil_image)

            h, w = image.shape[:2]
            return image, f"ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({w}x{h})ã€‚ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚"
        except Exception as e:
            return image, f"ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def load_from_path(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã¿"""
        if not file_path or not file_path.strip():
            return None, "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", ""

        file_path = file_path.strip()
        if not os.path.exists(file_path):
            return None, f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}", ""

        try:
            self.load_model()

            # ç”»åƒã‚’èª­ã¿è¾¼ã¿
            pil_image = Image.open(file_path).convert("RGB")
            image = np.array(pil_image)

            self.current_image = image.copy()
            self.current_image_path = file_path  # ãƒ‘ã‚¹ã‚’ä¿å­˜
            self.click_points = []
            self.click_labels = []

            self.inference_state = self.processor.set_image(pil_image)

            h, w = image.shape[:2]

            # æ·±åº¦ãƒãƒƒãƒ—ãƒ‘ã‚¹ã‚’è‡ªå‹•æ¨æ¸¬
            depth_path = self._guess_depth_path(file_path)

            return image, f"ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({w}x{h})ã€‚å‡ºåŠ›ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚", depth_path
        except Exception as e:
            return None, f"ã‚¨ãƒ©ãƒ¼: {str(e)}", ""

    def _guess_depth_path(self, rgb_path):
        """RGBãƒ‘ã‚¹ã‹ã‚‰æ·±åº¦ãƒãƒƒãƒ—ãƒ‘ã‚¹ã‚’æ¨æ¸¬"""
        # /workspace/experiments/session_xxx/rgb/frame_000002.jpg
        # â†’ /workspace/experiments/session_xxx/depth/frame_000002.npy
        if "/rgb/" in rgb_path:
            depth_path = rgb_path.replace("/rgb/", "/depth/")
            # æ‹¡å¼µå­ã‚’ .npy ã«å¤‰æ›´
            base = os.path.splitext(depth_path)[0]
            depth_path = base + ".npy"
            if os.path.exists(depth_path):
                return depth_path
        return ""

    def segment_click(self, image, evt: gr.SelectData):
        """ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ"""
        if self.inference_state is None:
            return image, "å…ˆã«ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

        try:
            # ã‚¯ãƒªãƒƒã‚¯åº§æ¨™ã‚’è¿½åŠ 
            x, y = evt.index
            self.click_points.append([x, y])
            self.click_labels.append(1)  # å‰æ™¯

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            masks, scores, _ = self.model.predict_inst(
                self.inference_state,
                point_coords=np.array(self.click_points),
                point_labels=np.array(self.click_labels),
                multimask_output=True
            )

            # ãƒ™ã‚¹ãƒˆãƒã‚¹ã‚¯ã‚’é¸æŠ
            best_idx = np.argmax(scores)
            best_mask = masks[best_idx]
            best_score = scores[best_idx]

            # ãƒã‚¹ã‚¯ã‚’ãƒ–ãƒ¼ãƒ«å‹ã«å¤‰æ›ï¼ˆNumPyã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¿…è¦ï¼‰
            if best_mask.dtype != bool:
                best_mask = best_mask > 0.5

            # ãƒã‚¹ã‚¯ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            overlay = self.current_image.copy()

            # é’è‰²ã®ãƒã‚¹ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            mask_color = np.array([30, 144, 255], dtype=np.float32)
            overlay = overlay.astype(np.float32)
            overlay[best_mask] = overlay[best_mask] * 0.5 + mask_color * 0.5

            # ã‚¯ãƒªãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
            for i, (px, py) in enumerate(self.click_points):
                # ç·‘è‰²ã®ç‚¹
                cv_y, cv_x = int(py), int(px)
                for dy in range(-5, 6):
                    for dx in range(-5, 6):
                        if dy*dy + dx*dx <= 25:  # åŠå¾„5ã®å††
                            ny, nx = cv_y + dy, cv_x + dx
                            if 0 <= ny < overlay.shape[0] and 0 <= nx < overlay.shape[1]:
                                overlay[ny, nx] = [0, 255, 0]

            overlay = overlay.astype(np.uint8)

            info = f"ã‚¹ã‚³ã‚¢: {best_score:.4f} | ã‚¯ãƒªãƒƒã‚¯æ•°: {len(self.click_points)} | ãƒã‚¹ã‚¯é¢ç©: {best_mask.sum() / best_mask.size * 100:.1f}%"

            return overlay, info
        except Exception as e:
            return image, f"ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def add_negative_point(self, image, evt: gr.SelectData):
        """èƒŒæ™¯ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ ï¼ˆå³ã‚¯ãƒªãƒƒã‚¯ç›¸å½“ï¼‰"""
        if self.inference_state is None:
            return image, "å…ˆã«ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

        # ã‚¯ãƒªãƒƒã‚¯åº§æ¨™ã‚’è¿½åŠ ï¼ˆèƒŒæ™¯ã¨ã—ã¦ï¼‰
        x, y = evt.index
        self.click_points.append([x, y])
        self.click_labels.append(0)  # èƒŒæ™¯

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        masks, scores, _ = self.model.predict_inst(
            self.inference_state,
            point_coords=np.array(self.click_points),
            point_labels=np.array(self.click_labels),
            multimask_output=True
        )

        # ãƒ™ã‚¹ãƒˆãƒã‚¹ã‚¯ã‚’é¸æŠ
        best_idx = np.argmax(scores)
        best_mask = masks[best_idx]
        best_score = scores[best_idx]

        # ãƒã‚¹ã‚¯ã‚’ãƒ–ãƒ¼ãƒ«å‹ã«å¤‰æ›ï¼ˆNumPyã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¿…è¦ï¼‰
        if best_mask.dtype != bool:
            best_mask = best_mask > 0.5

        # ãƒã‚¹ã‚¯ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        overlay = self.current_image.copy()
        mask_color = np.array([30, 144, 255], dtype=np.float32)
        overlay = overlay.astype(np.float32)
        overlay[best_mask] = overlay[best_mask] * 0.5 + mask_color * 0.5

        # ã‚¯ãƒªãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
        for i, ((px, py), label) in enumerate(zip(self.click_points, self.click_labels)):
            cv_y, cv_x = int(py), int(px)
            color = [0, 255, 0] if label == 1 else [255, 0, 0]  # ç·‘=å‰æ™¯, èµ¤=èƒŒæ™¯
            for dy in range(-5, 6):
                for dx in range(-5, 6):
                    if dy*dy + dx*dx <= 25:
                        ny, nx = cv_y + dy, cv_x + dx
                        if 0 <= ny < overlay.shape[0] and 0 <= nx < overlay.shape[1]:
                            overlay[ny, nx] = color

        overlay = overlay.astype(np.uint8)

        fg_count = sum(self.click_labels)
        bg_count = len(self.click_labels) - fg_count
        info = f"ã‚¹ã‚³ã‚¢: {best_score:.4f} | å‰æ™¯: {fg_count} | èƒŒæ™¯: {bg_count}"

        return overlay, info

    def reset(self):
        """ãƒªã‚»ãƒƒãƒˆ"""
        self.click_points = []
        self.click_labels = []
        if self.current_image is not None:
            return self.current_image, "ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚"
        return None, "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

    def save_mask(self):
        """ãƒã‚¹ã‚¯ã‚’ä¿å­˜"""
        if self.inference_state is None or not self.click_points:
            return "ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“"

        masks, scores, _ = self.model.predict_inst(
            self.inference_state,
            point_coords=np.array(self.click_points),
            point_labels=np.array(self.click_labels),
            multimask_output=True
        )

        best_mask = masks[np.argmax(scores)]

        # ãƒã‚¹ã‚¯ã‚’ãƒ–ãƒ¼ãƒ«å‹ã«å¤‰æ›
        if best_mask.dtype != bool:
            best_mask = best_mask > 0.5

        # ä¿å­˜
        save_path = "/workspace/experiments/sam3_demo_mask.npy"
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        np.save(save_path, best_mask)

        # PNGç”»åƒã‚‚ä¿å­˜
        mask_img = Image.fromarray((best_mask.astype(np.uint8) * 255))
        mask_img.save("/workspace/experiments/sam3_demo_mask.png")

        return f"ãƒã‚¹ã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}"

    def export_3d(self, depth_path):
        """ãƒã‚¹ã‚¯é ˜åŸŸã‚’3Dç‚¹ç¾¤ã¨ã—ã¦å‡ºåŠ›"""
        if self.inference_state is None or not self.click_points:
            return "ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚"

        if not depth_path or not depth_path.strip():
            return "æ·±åº¦ãƒãƒƒãƒ—ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"

        depth_path = depth_path.strip()
        if not os.path.exists(depth_path):
            return f"æ·±åº¦ãƒãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {depth_path}"

        try:
            # ãƒã‚¹ã‚¯ã‚’å–å¾—
            masks, scores, _ = self.model.predict_inst(
                self.inference_state,
                point_coords=np.array(self.click_points),
                point_labels=np.array(self.click_labels),
                multimask_output=True
            )
            best_mask = masks[np.argmax(scores)]
            if best_mask.dtype != bool:
                best_mask = best_mask > 0.5

            # ãƒã‚¹ã‚¯ã‚’ä¸€æ™‚ä¿å­˜
            mask_path = "/workspace/experiments/sam3_demo_mask.npy"
            os.makedirs(os.path.dirname(mask_path), exist_ok=True)
            np.save(mask_path, best_mask)

            # 3Då¤‰æ›
            from server.phase2_full.mask_to_3d import mask_to_3d
            output_path = "/workspace/experiments/segmented_object.ply"

            result = mask_to_3d(
                mask_path=mask_path,
                depth_path=depth_path,
                rgb_path=self.current_image_path,
                output_path=output_path,
            )

            return f"3Dç‚¹ç¾¤ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ!\n  ç‚¹ã®æ•°: {result['n_points']}\n  å‡ºåŠ›: {output_path}\n\nBlenderã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: File > Import > Stanford (.ply)"
        except Exception as e:
            return f"ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def export_rgba(self):
        """ãƒã‚¹ã‚¯é ˜åŸŸã‚’RGBAç”»åƒï¼ˆèƒŒæ™¯é€æ˜ï¼‰ã¨ã—ã¦å‡ºåŠ›"""
        if self.inference_state is None or not self.click_points:
            return "ãƒã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚"

        if self.current_image is None:
            return "ç”»åƒãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“"

        try:
            # ãƒã‚¹ã‚¯ã‚’å–å¾—
            masks, scores, _ = self.model.predict_inst(
                self.inference_state,
                point_coords=np.array(self.click_points),
                point_labels=np.array(self.click_labels),
                multimask_output=True
            )
            best_mask = masks[np.argmax(scores)]
            if best_mask.dtype != bool:
                best_mask = best_mask > 0.5

            # RGBAç”»åƒã‚’ä½œæˆ
            rgb = self.current_image.copy()
            h, w = rgb.shape[:2]

            # ã‚¢ãƒ«ãƒ•ã‚¡ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ä½œæˆï¼ˆãƒã‚¹ã‚¯é ˜åŸŸ=255ã€èƒŒæ™¯=0ï¼‰
            alpha = (best_mask.astype(np.uint8) * 255)

            # RGBAã«çµåˆ
            rgba = np.dstack([rgb, alpha])

            # ä¿å­˜
            output_dir = "/workspace/experiments"
            os.makedirs(output_dir, exist_ok=True)
            output_path = os.path.join(output_dir, "sam3_demo_rgba.png")

            rgba_img = Image.fromarray(rgba, mode='RGBA')
            rgba_img.save(output_path)

            # ãƒã‚¹ã‚¯ã‚‚ä¿å­˜
            mask_path = os.path.join(output_dir, "sam3_demo_mask.png")
            mask_img = Image.fromarray(alpha)
            mask_img.save(mask_path)

            return f"RGBAç”»åƒã‚’å‡ºåŠ›ã—ã¾ã—ãŸ!\n  å‡ºåŠ›: {output_path}\n  ãƒã‚¹ã‚¯: {mask_path}\n\nSAM 3D Objectsã®å…¥åŠ›ã«ä½¿ç”¨ã§ãã¾ã™"
        except Exception as e:
            return f"ã‚¨ãƒ©ãƒ¼: {str(e)}"


def get_sample_images():
    """ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—"""
    import glob
    samples = []

    # è¤‡æ•°ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
    search_dirs = [
        "/workspace/experiments",
        "/workspace/datasets",
    ]

    for sample_dir in search_dirs:
        if not os.path.exists(sample_dir):
            continue
        for pattern in ["**/rgb/*.jpg", "**/rgb/*.png", "**/*.jpg", "**/*.png"]:
            files = glob.glob(os.path.join(sample_dir, pattern), recursive=True)
            # ãƒã‚¹ã‚¯ç”»åƒã‚’é™¤å¤–
            files = [f for f in files if "mask" not in f.lower() and "depth" not in f.lower()]
            samples.extend(files[:10])

    # é‡è¤‡ã‚’é™¤å»ã—ã¦æœ€åˆã®10å€‹ã‚’è¿”ã™
    seen = set()
    unique = []
    for s in samples:
        if s not in seen:
            seen.add(s)
            unique.append(s)
    return unique[:10] if unique else None


def get_available_sessions():
    """åˆ©ç”¨å¯èƒ½ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—"""
    import glob
    sessions = []
    experiments_dir = "/workspace/experiments"

    if os.path.exists(experiments_dir):
        # session_* ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢
        session_dirs = glob.glob(os.path.join(experiments_dir, "session_*"))
        for session_dir in sorted(session_dirs, reverse=True):  # æ–°ã—ã„é †
            rgb_dir = os.path.join(session_dir, "rgb")
            if os.path.exists(rgb_dir):
                sessions.append(session_dir)

    return sessions


def get_session_thumbnails(session_dir):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒ€å†…ã®RGBç”»åƒã‚’ã‚µãƒ ãƒã‚¤ãƒ«ã¨ã—ã¦å–å¾—"""
    import glob

    if not session_dir or not os.path.exists(session_dir):
        return []

    rgb_dir = os.path.join(session_dir, "rgb")
    if not os.path.exists(rgb_dir):
        return []

    # JPGãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    files = sorted(glob.glob(os.path.join(rgb_dir, "*.jpg")))
    files += sorted(glob.glob(os.path.join(rgb_dir, "*.png")))

    # (ç”»åƒãƒ‘ã‚¹, ãƒ©ãƒ™ãƒ«) ã®ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆã‚’è¿”ã™
    thumbnails = [(f, os.path.basename(f)) for f in files[:20]]  # æœ€å¤§20æš
    return thumbnails


def create_demo():
    """Gradioãƒ‡ãƒ¢ã‚’ä½œæˆ"""
    demo_app = SAM3Demo()
    available_sessions = get_available_sessions()

    with gr.Blocks(title="SAM 3 Interactive Demo") as demo:
        gr.Markdown("""
        # SAM 3 Interactive Demo

        Meta AIã®Segment Anything Model 3ã‚’ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ†ã‚¹ãƒˆã§ãã¾ã™ã€‚

        ## ä½¿ã„æ–¹
        1. ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ
        2. ã‚µãƒ ãƒã‚¤ãƒ«ã‹ã‚‰ç”»åƒã‚’é¸æŠ
        3. å‡ºåŠ›ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        4. èƒŒæ™¯ãƒ¢ãƒ¼ãƒ‰ã‚’ONã«ã—ã¦é™¤å¤–ã—ãŸã„é ˜åŸŸã‚’ã‚¯ãƒªãƒƒã‚¯
        """)

        with gr.Row():
            with gr.Column(scale=1):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³é¸æŠ
                session_dropdown = gr.Dropdown(
                    choices=available_sessions,
                    label="ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒ€",
                    info="experimentsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é¸æŠ",
                    value=available_sessions[0] if available_sessions else None
                )
                refresh_btn = gr.Button("ğŸ”„ ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°", size="sm")

                # ã‚µãƒ ãƒã‚¤ãƒ«ã‚®ãƒ£ãƒ©ãƒªãƒ¼
                thumbnail_gallery = gr.Gallery(
                    label="RGBç”»åƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã§é¸æŠï¼‰",
                    columns=4,
                    rows=2,
                    height=200,
                    object_fit="cover",
                    allow_preview=False
                )

                gr.Markdown("---")

                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆè‡ªå‹•è¨­å®šã•ã‚Œã‚‹ï¼‰
                file_path_input = gr.Textbox(
                    label="RGBãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
                    placeholder="ä¸Šã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨è‡ªå‹•è¨­å®šã•ã‚Œã¾ã™",
                    info="ã¾ãŸã¯ç›´æ¥ãƒ‘ã‚¹ã‚’å…¥åŠ›"
                )
                load_path_btn = gr.Button("ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã‚€", variant="primary")

                with gr.Row():
                    reset_btn = gr.Button("ãƒªã‚»ãƒƒãƒˆ", variant="secondary")
                    save_btn = gr.Button("ãƒã‚¹ã‚¯ä¿å­˜", variant="secondary")
                bg_mode = gr.Checkbox(label="èƒŒæ™¯ãƒ¢ãƒ¼ãƒ‰ï¼ˆé™¤å¤–é ˜åŸŸã‚’ã‚¯ãƒªãƒƒã‚¯ï¼‰", value=False)

                # å‡ºåŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                gr.Markdown("---\n#### å‡ºåŠ›")
                export_rgba_btn = gr.Button("RGBAç”»åƒã‚’å‡ºåŠ› (SAM 3Dç”¨)", variant="primary")

                depth_path_input = gr.Textbox(
                    label="æ·±åº¦ãƒãƒƒãƒ—ãƒ‘ã‚¹",
                    placeholder="è‡ªå‹•è¨­å®šã•ã‚Œã¾ã™",
                    info="æ·±åº¦ãƒãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.npyï¼‰"
                )
                export_3d_btn = gr.Button("3Dç‚¹ç¾¤ã‚’å‡ºåŠ› (PLY)", variant="secondary")

            with gr.Column(scale=2):
                output_image = gr.Image(label="ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµæœï¼ˆã“ã“ã‚’ã‚¯ãƒªãƒƒã‚¯ï¼‰", height=600)
                info_text = gr.Textbox(label="æƒ…å ±", interactive=False)
                save_result = gr.Textbox(label="ä¿å­˜çµæœ", interactive=False, lines=3)

        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³é¸æŠæ™‚ã«ã‚µãƒ ãƒã‚¤ãƒ«ã‚’æ›´æ–°
        def update_thumbnails(session_dir):
            thumbnails = get_session_thumbnails(session_dir)
            return thumbnails

        session_dropdown.change(
            update_thumbnails,
            inputs=session_dropdown,
            outputs=thumbnail_gallery
        )

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°ãƒœã‚¿ãƒ³
        def refresh_sessions():
            sessions = get_available_sessions()
            return gr.Dropdown(choices=sessions, value=sessions[0] if sessions else None)

        refresh_btn.click(
            refresh_sessions,
            outputs=session_dropdown
        )

        # ã‚µãƒ ãƒã‚¤ãƒ«ã‚¯ãƒªãƒƒã‚¯æ™‚ã«ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¦èª­ã¿è¾¼ã¿
        def on_thumbnail_select(session_dir, evt: gr.SelectData):
            thumbnails = get_session_thumbnails(session_dir)
            if evt.index < len(thumbnails):
                selected_path = thumbnails[evt.index][0]
                # ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§è¿”ã™
                result = demo_app.load_from_path(selected_path)
                return selected_path, result[0], result[1], result[2]
            return "", None, "ã‚µãƒ ãƒã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", ""

        thumbnail_gallery.select(
            on_thumbnail_select,
            inputs=session_dropdown,
            outputs=[file_path_input, output_image, info_text, depth_path_input]
        )

        # åˆæœŸè¡¨ç¤ºï¼šæœ€åˆã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚’è¡¨ç¤º
        demo.load(
            update_thumbnails,
            inputs=session_dropdown,
            outputs=thumbnail_gallery
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆæ·±åº¦ãƒ‘ã‚¹ã‚‚è‡ªå‹•è¨­å®šï¼‰
        load_path_btn.click(
            demo_app.load_from_path,
            inputs=file_path_input,
            outputs=[output_image, info_text, depth_path_input]
        )

        def handle_click(bg_mode, evt: gr.SelectData):
            if bg_mode:
                return demo_app.add_negative_point(None, evt)
            else:
                return demo_app.segment_click(None, evt)

        output_image.select(
            handle_click,
            inputs=[bg_mode],
            outputs=[output_image, info_text]
        )

        reset_btn.click(
            demo_app.reset,
            outputs=[output_image, info_text]
        )

        save_btn.click(
            demo_app.save_mask,
            outputs=save_result
        )

        export_3d_btn.click(
            demo_app.export_3d,
            inputs=depth_path_input,
            outputs=save_result
        )

        export_rgba_btn.click(
            demo_app.export_rgba,
            outputs=save_result
        )

        gr.Markdown("""
        ---
        ## ãƒ’ãƒ³ãƒˆ
        - è¤‡æ•°å›ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒæ´—ç·´ã•ã‚Œã¾ã™
        - èƒŒæ™¯ãƒ¢ãƒ¼ãƒ‰ã‚’ONã«ã—ã¦ã€é™¤å¤–ã—ãŸã„éƒ¨åˆ†ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™
        - **RGBAå‡ºåŠ›**: SAM 3D Objectsã®å…¥åŠ›ç”¨ã«èƒŒæ™¯é€æ˜ã®ç”»åƒã‚’å‡ºåŠ›
        - **3Då‡ºåŠ›**: æ·±åº¦ãƒãƒƒãƒ—ãŒã‚ã‚Œã°ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé ˜åŸŸã‚’3Dç‚¹ç¾¤ï¼ˆPLYï¼‰ã¨ã—ã¦å‡ºåŠ›
        """)

    return demo


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="SAM 3 Interactive Demo")
    parser.add_argument("--port", type=int, default=7860, help="ãƒãƒ¼ãƒˆç•ªå·")
    parser.add_argument("--share", action="store_true", help="å…¬é–‹ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ")
    args = parser.parse_args()

    print("=" * 50)
    print("SAM 3 Interactive Demo")
    print("=" * 50)
    print(f"ãƒãƒ¼ãƒˆ: {args.port}")
    print(f"URL: http://0.0.0.0:{args.port}")
    print("=" * 50)

    demo = create_demo()
    demo.launch(
        server_name="0.0.0.0",
        server_port=args.port,
        share=args.share,
        max_file_size="50mb",  # æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å¢—ã‚„ã™
    )


if __name__ == "__main__":
    main()
